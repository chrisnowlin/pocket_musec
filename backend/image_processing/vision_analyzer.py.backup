"""Vision analyzer using Chutes Vision API for semantic understanding"""

import requests
import base64
from pathlib import Path
from typing import Optional, Dict, List, Tuple
import os
import logging
import json
import re

from backend.config import config

logger = logging.getLogger(__name__)


class VisionAnalyzer:
    """
    Analyzes images using vision AI models

    Provides semantic understanding of visual content beyond OCR
    """

    def __init__(
        self, api_key: Optional[str] = None, api_base_url: Optional[str] = None
    ):
        """
        Initialize vision analyzer

        Args:
            api_key: Chutes API key (or from env)
            api_base_url: Chutes API base URL (or from env)
        """
        self.api_key = api_key or config.chutes.api_key
        self.api_base_url = api_base_url or config.chutes.base_url

        if not self.api_key:
            logger.warning("CHUTES_API_KEY not set, vision analysis will be disabled")

    def analyze_image(
        self,
        image_path: str,
        prompt: str = "Describe this image in detail, focusing on any musical notation, instruments, educational content, or instructional diagrams.",
        structured_output: bool = False,
    ) -> Optional[str]:
        """
        Analyze image using vision model

        Args:
            image_path: Path to image file
            prompt: Analysis prompt for the vision model
            structured_output: Whether to request structured JSON output

        Returns:
            Analysis text or None if failed
        """
        if not self.api_key:
            logger.warning("Vision analysis skipped: API key not configured")
            return None

        try:
            # Read and encode image
            with open(image_path, "rb") as f:
                image_data = base64.b64encode(f.read()).decode("utf-8")

            # Determine image format
            suffix = Path(image_path).suffix.lower()
            mime_type = self._get_mime_type(suffix)

            # Call Chutes Vision API
            response = requests.post(
                f"{self.api_base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": "Qwen/Qwen3-VL-235B-A22B-Instruct",
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:{mime_type};base64,{image_data}"
                                    },
                                },
                            ],
                        }
                    ],
                    "max_tokens": 500,
                    "temperature": 0.3,
                },
                timeout=30,
            )

            response.raise_for_status()
            result = response.json()

            # Extract analysis from response
            analysis = result["choices"][0]["message"]["content"]

            logger.info(f"Vision analysis completed: {len(analysis)} characters")
            return analysis

        except requests.exceptions.RequestException as e:
            logger.error(f"Vision API request failed: {e}")
            return None
        except Exception as e:
            logger.error(f"Vision analysis failed: {e}")
            return None

    def analyze_sheet_music(self, image_path: str) -> Optional[Dict[str, str]]:
        """
        Specialized analysis for sheet music

        Args:
            image_path: Path to sheet music image

        Returns:
            Dictionary with musical elements or None
        """
        prompt = """Analyze this sheet music image and provide:
1. Composer and title (if visible)
2. Time signature
3. Key signature
4. Tempo markings
5. Notable musical elements (dynamics, articulations, etc.)
6. Difficulty level estimate
7. Musical period or style

Format the response as a structured analysis."""

        analysis = self.analyze_image(image_path, prompt)

        if analysis:
            return {"type": "sheet_music", "analysis": analysis}
        return None

    def analyze_diagram(self, image_path: str) -> Optional[Dict[str, str]]:
        """
        Specialized analysis for instructional diagrams

        Args:
            image_path: Path to diagram image

        Returns:
            Dictionary with diagram elements or None
        """
        prompt = """Analyze this educational diagram and provide:
1. Main topic or concept being illustrated
2. Key visual elements and their relationships
3. Any text labels or annotations
4. Educational purpose or learning objective
5. Target audience level (beginner, intermediate, advanced)

Format the response as a structured analysis."""

        analysis = self.analyze_image(image_path, prompt)

        if analysis:
            return {"type": "instructional_diagram", "analysis": analysis}
        return None

    def extract_elements(self, image_path: str) -> Optional[Dict[str, any]]:
        """
        Extract specific elements from image

        Args:
            image_path: Path to image file

        Returns:
            Dictionary with categorized elements or None
        """
        prompt = """List all distinct elements in this image:
        - Musical instruments (if any)
        - Musical notation elements (notes, rests, clefs, etc.)
        - Text labels and annotations
        - Diagrams or charts
        - People or performers
        - Educational symbols

        Provide a structured list."""

        analysis = self.analyze_image(image_path, prompt)

        if analysis:
            # Parse elements from analysis
            # This is a simplified version; could be enhanced with structured output
            elements_list = [
                line.strip() for line in analysis.split("\n") if line.strip()
            ]
            return {
                "elements": elements_list,
                "raw_analysis": analysis,
                "element_count": len(elements_list),
            }
        return None

    def _get_mime_type(self, suffix: str) -> str:
        """Get MIME type from file suffix"""
        mime_types = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".gif": "image/gif",
            ".webp": "image/webp",
            ".tiff": "image/tiff",
            ".tif": "image/tiff",
        }
        return mime_types.get(suffix, "image/jpeg")

    def analyze_image_structured(
        self, image_path: str, analysis_type: str = "general"
    ) -> Optional[Dict]:
        """
        Analyze image with structured JSON output

        Args:
            image_path: Path to image file
            analysis_type: Type of analysis (general, sheet_music, diagram, instruments)

        Returns:
            Structured analysis dictionary or None if failed
        """
        if not self.api_key:
            logger.warning("Vision analysis skipped: API key not configured")
            return None

        prompts = {
            "general": """Analyze this image and provide a structured JSON response with:
            {
                "image_type": "sheet_music|instructional_diagram|instruments|general",
                "confidence_score": 0.0-1.0,
                "main_subject": "brief description",
                "key_elements": ["element1", "element2"],
                "text_content": "any readable text",
                "educational_context": "music_education|general_education|other",
                "difficulty_level": "beginner|intermediate|advanced|unknown",
                "description": "detailed description"
            }""",
            "sheet_music": """Analyze this sheet music image and provide structured JSON:
            {
                "image_type": "sheet_music",
                "confidence_score": 0.0-1.0,
                "title": "piece title if visible",
                "composer": "composer name if visible",
                "key_signature": "e.g., C major, G minor",
                "time_signature": "e.g., 4/4, 3/4",
                "tempo": "tempo marking if visible",
                "instruments": ["instrument1", "instrument2"],
                "difficulty_level": "beginner|intermediate|advanced",
                "musical_elements": ["clefs", "key_signature", "time_signature", "dynamics"],
                "description": "detailed musical analysis"
            }""",
            "diagram": """Analyze this educational diagram and provide structured JSON:
            {
                "image_type": "instructional_diagram",
                "confidence_score": 0.0-1.0,
                "topic": "main subject area",
                "concept_type": "theory|technique|history|other",
                "visual_elements": ["charts", "labels", "symbols"],
                "text_labels": ["label1", "label2"],
                "educational_level": "elementary|middle_school|high_school|college",
                "learning_objective": "what students should learn",
                "description": "detailed diagram analysis"
            }""",
            "instruments": """Analyze this musical instrument image and provide structured JSON:
            {
                "image_type": "instruments",
                "confidence_score": 0.0-1.0,
                "instruments_identified": ["instrument1", "instrument2"],
                "instrument_family": "strings|woodwinds|brass|percussion|keyboard",
                "playing_technique": "bowing|plucking|blowing|striking|unknown",
                "context": "performance|instruction|maintenance|display",
                "skill_level": "beginner|intermediate|advanced|unknown",
                "description": "detailed instrument analysis"
            }""",
        }

        prompt = prompts.get(analysis_type, prompts["general"])

        try:
            # Read and encode image
            with open(image_path, "rb") as f:
                image_data = base64.b64encode(f.read()).decode("utf-8")

            # Determine image format
            suffix = Path(image_path).suffix.lower()
            mime_type = self._get_mime_type(suffix)

            # Call Chutes Vision API with structured output request
            response = requests.post(
                f"{self.api_base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": "Qwen/Qwen3-VL-235B-A22B-Instruct",
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": prompt
                                    + "\n\nRespond with valid JSON only.",
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:{mime_type};base64,{image_data}"
                                    },
                                },
                            ],
                        }
                    ],
                    "max_tokens": 800,
                    "temperature": 0.1,  # Lower temperature for more consistent structured output
                },
                timeout=45,
            )

            response.raise_for_status()
            result = response.json()

            # Extract analysis from response
            analysis = result["choices"][0]["message"]["content"]

            # Parse JSON response
            try:
                structured_data = json.loads(analysis)
                logger.info(f"Structured vision analysis completed: {analysis_type}")
                return structured_data
            except json.JSONDecodeError:
                # Fallback: try to extract JSON from text
                json_match = re.search(r"\{.*\}", analysis, re.DOTALL)
                if json_match:
                    try:
                        structured_data = json.loads(json_match.group())
                        logger.info(
                            f"Structured vision analysis completed (fallback): {analysis_type}"
                        )
                        return structured_data
                    except json.JSONDecodeError:
                        pass

                # If JSON parsing fails, return unstructured analysis
                logger.warning(
                    "Failed to parse structured JSON, returning unstructured analysis"
                )
                return {
                    "image_type": "unknown",
                    "confidence_score": 0.5,
                    "description": analysis,
                    "parse_error": True,
                }

        except requests.exceptions.RequestException as e:
            logger.error(f"Vision API request failed: {e}")
            return None
        except Exception as e:
            logger.error(f"Structured vision analysis failed: {e}")
            return None

    def extract_musical_elements(
        self, image_path: str
    ) -> Optional[Dict[str, List[str]]]:
        """
        Extract specific musical elements from image

        Args:
            image_path: Path to image file

        Returns:
            Dictionary with categorized musical elements or None
        """
        prompt = """Identify and list all musical elements in this image. Return JSON:
        {
            "notation_elements": ["treble_clef", "bass_clef", "notes", "rests"],
            "symbols": ["sharp", "flat", "natural", "dynamic_markings"],
            "text_elements": ["title", "composer", "lyrics", "instructions"],
            "structural_elements": ["measures", "bar_lines", "repeat_signs"],
            "instruments": ["piano", "violin", "flute"],
            "confidence_score": 0.8
        }"""

        return self.analyze_image_structured(image_path, "general")

    def calculate_analysis_confidence(self, structured_data: Dict) -> float:
        """
        Calculate overall confidence score for analysis

        Args:
            structured_data: Structured analysis data

        Returns:
            Confidence score between 0.0 and 1.0
        """
        if not structured_data:
            return 0.0

        # Use provided confidence score if available
        if "confidence_score" in structured_data:
            try:
                return float(structured_data["confidence_score"])
            except (ValueError, TypeError):
                pass

        # Calculate confidence based on data completeness
        required_fields = ["image_type", "description"]
        optional_fields = ["key_elements", "text_content", "educational_context"]

        present_required = sum(
            1 for field in required_fields if structured_data.get(field)
        )
        present_optional = sum(
            1 for field in optional_fields if structured_data.get(field)
        )

        base_confidence = present_required / len(required_fields)
        bonus_confidence = (present_optional / len(optional_fields)) * 0.2

        return min(1.0, base_confidence + bonus_confidence)

    def batch_analyze_images(
        self, image_paths: List[str], analysis_type: str = "general"
    ) -> List[Tuple[str, Optional[Dict]]]:
        """
        Analyze multiple images in batch

        Args:
            image_paths: List of image file paths
            analysis_type: Type of analysis to perform

        Returns:
            List of (image_path, analysis_result) tuples
        """
        results = []

        for image_path in image_paths:
            try:
                analysis = self.analyze_image_structured(image_path, analysis_type)
                results.append((image_path, analysis))
                logger.info(f"Batch analysis completed for: {Path(image_path).name}")
            except Exception as e:
                logger.error(f"Batch analysis failed for {image_path}: {e}")
                results.append((image_path, None))

        return results

    def is_available(self) -> bool:
        """Check if vision analysis is available"""
        return bool(self.api_key)
